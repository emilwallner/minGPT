{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import datetime\n",
    "from mingpt.md import MemData\n",
    "from mingpt.marker_dataset import MarkerDataset\n",
    "from mingpt.math_dataset import MathDataset\n",
    "from mingpt.model import GPT, GPTConfig, GPT1Config\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "from mingpt.examiner import Examiner\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset\n",
    "!rm -rf run\n",
    "!cp -r data run\n",
    "fn_data = 'run/numbers__list_prime_factors.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add memory data structure to training data\n",
    "memory_slots = 7\n",
    "MD = MemData(memory_slots)\n",
    "MD.initiate_mem_slot_data(fn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_test = 'run/test_numbers__list_prime_factors.txt'\n",
    "fn_train = 'run/train_numbers__list_prime_factors.txt'\n",
    "train_dataset = MathDataset(fname=fn_train, MD=MD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MD.block_size)\n",
    "print(MD.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a baby GPT model\n",
    "mconf = GPTConfig(MD.vocab_size, MD.block_size, \n",
    "                  n_layer=2, n_head=4, n_embd=128)\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_it = 100\n",
    "main_epoch = 1\n",
    "marker_epoch = 1\n",
    "current_it = 0\n",
    "\n",
    "exp_folder = datetime.datetime.now().strftime('%Y-%m-%d~%H:%M:%S')\n",
    "examiner = Examiner(MD)\n",
    "\n",
    "\n",
    "# Switch between main training and marker training\n",
    "print(\"Loading Main Dataset\\n\")\n",
    "train_dataset = MathDataset(fname=fn_train, MD=MD)\n",
    "test_dataset = MathDataset(fname=fn_test, MD=MD)\n",
    "epoch = main_epoch\n",
    "\n",
    "# print(\"Loading Marker Dataset\\n\")\n",
    "# train_dataset = MarkerDataset(fname=fn_train, MD=MD)\n",
    "# test_dataset = MarkerDataset(fname=fn_test, MD=MD)\n",
    "# epoch = marker_epoch\n",
    "\n",
    "# Trainer Config\n",
    "tconf = TrainerConfig(max_epochs=epoch, batch_size=1024, learning_rate=6e-4,\n",
    "                  lr_decay=True, warmup_tokens=1024, final_tokens=50*len(train_dataset)*(14+1),\n",
    "                  num_workers=0)\n",
    "\n",
    "# Create the first training round\n",
    "print(\"Training-------------------\\n\")\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
    "#trainer.train()\n",
    "#trainer.save_checkpoint(exp_folder, str(current_it))\n",
    "\n",
    "\n",
    "print(\"Exam and new dataset-------------\\n\")\n",
    "examiner.exam(fn_train, train_dataset, trainer, 10000)\n",
    "examiner.exam(fn_test, test_dataset, trainer, 10000)\n",
    "\n",
    "train_dataset = MarkerDataset(fname=fn_train, MD=MD)\n",
    "test_dataset = MarkerDataset(fname=fn_test, MD=MD)\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
    "trainer.train()\n",
    "\n",
    "train_dataset = MathDataset(fname=fn_train, MD=MD)\n",
    "test_dataset = MathDataset(fname=fn_test, MD=MD)\n",
    "\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
    "trainer.train()\n",
    "\n",
    "examiner.exam(fn_train, train_dataset, trainer)\n",
    "examiner.exam(fn_test, test_dataset, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MarkerDataset(fname=fn_train, MD=MD)\n",
    "test_dataset = MarkerDataset(fname=fn_test, MD=MD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
