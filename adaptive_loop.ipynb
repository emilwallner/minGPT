{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import datetime\n",
    "from mingpt.md import MemData\n",
    "from mingpt.math_dataset import MathDataset\n",
    "from mingpt.model import GPT, GPTConfig, GPT1Config\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "from mingpt.adaptive_examiner import AdaptiveExaminer\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataset\n",
    "!rm -rf run models\n",
    "!cp -r data run\n",
    "#!mkdir models\n",
    "fn_data = 'run/numbers__list_prime_factors.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add memory data structure to training data\n",
    "memory_slots = 7\n",
    "MD = MemData(memory_slots)\n",
    "MD.initiate_mem_slot_data(fn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_test = 'run/test_numbers__list_prime_factors.txt'\n",
    "fn_train = 'run/train_numbers__list_prime_factors.txt'\n",
    "train_dataset = MathDataset(fname=fn_train, MD=MD, marker_data=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MD.tensor2string(train_dataset[4][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n",
      "102\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(MD.block_size)\n",
    "print(MD.vocab_size)\n",
    "print(MD.max_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a baby GPT model\n",
    "#mconf = GPTConfig(MD.vocab_size, MD.block_size,\n",
    "#                  n_layer=4, n_head=8, n_embd=256)\n",
    "#model = GPT(mconf)\n",
    "model = torch.load('9.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marker Data:  0.2\n",
      "Training:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 25: train loss 1.51930. lr 5.991565e-04: 100%|██████████| 26/26 [00:12<00:00,  2.17it/s]\n",
      "12/20/2020 05:44:06 - INFO - mingpt.trainer -   test loss: 1.480862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Loss:  1.480862021446228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 iter 25: train loss 1.38583. lr 5.965892e-04: 100%|██████████| 26/26 [00:11<00:00,  2.22it/s]\n",
      "12/20/2020 05:44:19 - INFO - mingpt.trainer -   test loss: 1.388755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Loss:  1.388754924138387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 iter 25: train loss 1.39443. lr 5.922484e-04: 100%|██████████| 26/26 [00:11<00:00,  2.22it/s]\n",
      "12/20/2020 05:44:31 - INFO - mingpt.trainer -   test loss: 1.356751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Loss:  1.3567509253819783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 iter 25: train loss 1.25347. lr 5.862644e-04: 100%|██████████| 26/26 [00:11<00:00,  2.22it/s]\n",
      "12/20/2020 05:44:43 - INFO - mingpt.trainer -   test loss: 1.349944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Loss:  1.349943995475769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 iter 25: train loss 1.42814. lr 5.786254e-04: 100%|██████████| 26/26 [00:11<00:00,  2.22it/s]\n",
      "12/20/2020 05:44:56 - INFO - mingpt.trainer -   test loss: 1.322997\n",
      "12/20/2020 05:44:56 - INFO - mingpt.trainer -   saving models/2020-12-20~05:43:53/7.pth\n",
      "Iiter 1 Score: 0/2:   0%|          | 2/9000 [00:00<12:16, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Loss:  1.3229968547821045\n",
      "Exam and new dataset-------------\n",
      "\n",
      "Training exam \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iiter 8999 Score: 0/28355: 100%|██████████| 9000/9000 [01:04<00:00, 139.00it/s]\n",
      "  0%|          | 0/28355 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Compute Iteration:  0\n",
      "Result: 0/28355 = 0.00% correct\n",
      "Predictions: 0/28355 = 0.00% correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iiter 7904 Score: 0/47664:  28%|██▊       | 8044/28355 [01:43<11:56, 28.33it/s] "
     ]
    }
   ],
   "source": [
    "max_it = 100\n",
    "current_it = 7\n",
    "\n",
    "exp_folder = 'models/' + datetime.datetime.now().strftime('%Y-%m-%d~%H:%M:%S')\n",
    "examiner = AdaptiveExaminer(MD)\n",
    "\n",
    "while(current_it < max_it):\n",
    "    \n",
    "    # Wait until the working memory is filled, then use 5 epochs\n",
    "    epoch = 1 if current_it < 7 else 5\n",
    "    # Use marker data once the working memory is full\n",
    "    marker_data = 0.0 if current_it < 7 else 0.2\n",
    "    \n",
    "    # Switch between main training and marker training\n",
    "    print(\"Marker Data: \", str(marker_data))\n",
    "    train_dataset = MathDataset(fname=fn_train, MD=MD, marker_data=marker_data)\n",
    "    test_dataset = MathDataset(fname=fn_test, MD=MD, marker_data=0.0)\n",
    "    \n",
    "    # Trainer Config\n",
    "    tconf = TrainerConfig(max_epochs=epoch, batch_size=358, learning_rate=6e-4,\n",
    "                      lr_decay=True, warmup_tokens=1024, final_tokens=epoch*len(train_dataset)*(MD.vocab_size+1),\n",
    "                      num_workers=6)\n",
    "    \n",
    "    # Create the first training round\n",
    "    print(\"Training: \", str(current_it))\n",
    "    trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
    "    trainer.train()\n",
    "    trainer.save_checkpoint(exp_folder, str(current_it))\n",
    "    \n",
    "    # Examine the model and create new dataset\n",
    "    \n",
    "    print(\"Exam and new dataset-------------\\n\")\n",
    "    print(\"Training exam \\n\")\n",
    "    examiner.exam(fn_train, trainer, 5000)\n",
    "    print(\"Test exam \\n\")\n",
    "    #examiner.exam(fn_test, trainer)\n",
    "    \n",
    "    current_it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(True == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = True\n",
    "hat = False\n",
    "print(f\"This is a {cat}, and this is a {hat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"foo.txt\", \"a\") as f:\n",
    "     f.write(\"3new line\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(None, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
