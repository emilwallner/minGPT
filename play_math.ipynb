{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GPT on addition\n",
    "\n",
    "Train a GPT model on a dedicated addition dataset to see if a Transformer can learn to add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from mingpt.md import MemData\n",
    "from mingpt.marker_dataset import MarkerDataset\n",
    "from mingpt.math_dataset import MathDataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset \n",
    "easy = 'run/numbers__place_value.txt'\n",
    "medium = 'run/numbers__is_prime.txt'\n",
    "hard = 'run/numbers__list_prime_factors.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf run\n",
    "!cp -r data run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_slots = 7\n",
    "MD = MemData(memory_slots)\n",
    "MD.initiate_mem_slot_data(hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset \n",
    "easy_test = 'run/test_numbers__place_value.txt'\n",
    "medium_test = 'run/test_numbers__is_prime.txt'\n",
    "hard_test = 'run/test_numbers__list_prime_factors.txt'\n",
    "easy_train = 'run/train_buffer_numbers__place_value.txt'\n",
    "medium_train = 'run/train_buffer_numbers__is_prime.txt'\n",
    "hard_train = 'run/train_buffer_numbers__list_prime_factors.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MathDataset(fname=hard_train, MD=MD)\n",
    "test_dataset = MathDataset(fname=hard_test, MD=MD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MD.block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'List the prime factors of 792802.answermemmemmemmemmemmemmemmem-end2, 29, 13669padpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpad'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MD.tensor2string(train_dataset[1000][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2020 09:09:31 - INFO - mingpt.model -   number of parameters: 4.592640e+05\n"
     ]
    }
   ],
   "source": [
    "from mingpt.model import GPT, GPTConfig, GPT1Config\n",
    "\n",
    "# initialize a baby GPT model\n",
    "mconf = GPTConfig(MD.vocab_size, MD.block_size, \n",
    "                  n_layer=2, n_head=4, n_embd=128)\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1171: train loss 1.38753. lr 5.993840e-04: 100%|██████████| 1172/1172 [04:46<00:00,  4.09it/s]\n",
      "11/21/2020 09:14:39 - INFO - mingpt.trainer -   test loss: 1.361612\n",
      "11/21/2020 09:14:39 - INFO - mingpt.trainer -   saving model.pth\n"
     ]
    }
   ],
   "source": [
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "\n",
    "# initialize a trainer instance and kick off training\n",
    "tconf = TrainerConfig(max_epochs=1, batch_size=512, learning_rate=6e-4,\n",
    "                      lr_decay=True, warmup_tokens=1024, final_tokens=50*len(train_dataset)*(14+1),\n",
    "                      num_workers=0)\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2020 09:14:39 - INFO - mingpt.trainer -   saving model.pth\n"
     ]
    }
   ],
   "source": [
    "trainer.save_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f062234bae42458d40ec77e31ab772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final score: 0/11 = 0.00% correct\n",
      "Saving new files to disk...\n"
     ]
    }
   ],
   "source": [
    "# now let's give the trained model an addition exam\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from mingpt.examiner import Examiner\n",
    "examiner = Examiner(MD)\n",
    "examiner.exam(hard_train, train_dataset, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training set: how well did we memorize?\n",
    "examples = give_exam(test_dataset, batch_size=1, max_batches=-1)\n",
    "print(\"Q: %s\\nX:%s\\nO:%s\\n\" % (examples[0][0], examples[0][1] , examples[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in examples:\n",
    "    print(\"Question:\", item[0])\n",
    "    print(\"X:\", item[1])\n",
    "    print(\"Out:\", item[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set: how well did we generalize?\n",
    "give_exam(train_dataset, batch_size=1024, max_batches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# well that's amusing... our model learned everything except 55 + 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ['-1', '-1', '2', '1', '1']\n",
    "\n",
    "it.takewhile(lambda x: x!='2', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
